{"editor":{"base":{"vertex":{"source":"//vertex position in world coordinates\nattribute vec3 vertex_worldSpace;\n//surface normal at the vertex in world coordinates\nattribute vec3 normal_worldSpace;\n//texture coordinates at that vertex\nattribute vec2 textureCoordinate_input;\n\n//model Matrix (Identity in our case)\nuniform mat4 mMatrix;\n//view Matrix\nuniform mat4 vMatrix;\n//projection Matrix\nuniform mat4 pMatrix;\n\n//main program for each vertex\nvoid main() {\n  vec4 vertex_camSpace = vMatrix * mMatrix * vec4(vertex_worldSpace, 1.0);\n  gl_Position = pMatrix * vertex_camSpace;\n\n\n}","isLinked":true},"fragment":{"source":"//for better performance less precision\nprecision mediump float;\n\n//main program for each fragment = pixel candidate\nvoid main() {\n  gl_FragColor = vec4(1.0, 0.0, 0.0, 1.0);\n}","isLinked":true}},"R2T":{"vertex":{"source":"//vertex coordinates in world space for the render quad\nattribute vec3 vertex_worldSpace;\n//texture coordinate for this vertex and the render quad\nattribute vec2 textureCoordinate_input;\n\n//texture coordinate needs to be passed on to the R2T fragment shader\nvarying vec2 textureUV;\n\n//main program for each vertex of the render quad\nvoid main() {\n  gl_Position = vec4(vertex_worldSpace, 1.0);\n  textureUV = textureCoordinate_input;\n}","isLinked":true},"fragment":{"source":"precision mediump float;\n\n//a texture sampling unit, which is bound to the render quad texture buffer\nuniform sampler2D renderedTexture;\n\n//texture coordinates coming from the vertex shader, interpolated through the rasterizer\nvarying vec2 textureUV;\n\n//main program for each fragment of the render quad\nvoid main() {\n  float s[12];\n  s[0] = -0.10568;   s[1]  = -0.07568;    s[2]  = -0.042158;\n  s[3] = -0.02458;   s[4]  = -0.01987456; s[5]  = -0.0112458;\n  s[6] =  0.0112458; s[7]  =  0.01987456; s[8]  =  0.02458;\n  s[9] =  0.042158;  s[10] =  0.07568;    s[11] =  0.10568;\n\n  // Samples\n  int n = 12;\n\n  // Center of image\n  vec2 c = vec2(0.5, 0.5);\n\n  // Normalized direction to center of image\n  vec2 p_v = normalize(c - textureUV);\n  \n  // Max distance for sampling\n  float d_max = 0.3;\n\n  vec3 tex_sum = vec3(0, 0, 0);\n  tex_sum += texture2D(renderedTexture, textureUV + p_v * (s[0] * d_max)).xyz;\n  tex_sum += texture2D(renderedTexture, textureUV + p_v * (s[1] * d_max)).xyz;\n  tex_sum += texture2D(renderedTexture, textureUV + p_v * (s[2] * d_max)).xyz;\n  tex_sum += texture2D(renderedTexture, textureUV + p_v * (s[3] * d_max)).xyz;\n  tex_sum += texture2D(renderedTexture, textureUV + p_v * (s[4] * d_max)).xyz;\n  tex_sum += texture2D(renderedTexture, textureUV + p_v * (s[5] * d_max)).xyz;\n  tex_sum += texture2D(renderedTexture, textureUV + p_v * (s[6] * d_max)).xyz;\n  tex_sum += texture2D(renderedTexture, textureUV + p_v * (s[7] * d_max)).xyz;\n  tex_sum += texture2D(renderedTexture, textureUV + p_v * (s[8] * d_max)).xyz;\n  tex_sum += texture2D(renderedTexture, textureUV + p_v * (s[9] * d_max)).xyz;\n  tex_sum += texture2D(renderedTexture, textureUV + p_v * (s[10] * d_max)).xyz;\n  tex_sum += texture2D(renderedTexture, textureUV + p_v * (s[11] * d_max)).xyz;\n\n  vec3 rgb_blur = tex_sum / float(n);\n  gl_FragColor = vec4(rgb_blur, 1);\n}","isLinked":true}}},"camera":{"position":[0,0,37],"target":[0,0,0],"nearClipping":0.1,"farClipping":1000,"projection":"Perspective","perspectiveFov":45,"orthographicFov":30},"model":{"mesh":"teapot","position":[0,-8,0],"rotationAxis":[1,0,0],"rotationAngle":-90,"scale":[1,1,1],"depthTest":"LESS","faceCulling":"","frontFace":"CCW"},"uniforms":{"base":{"value":{"mMatrix":{"attachment":"Model Matrix"},"vMatrix":{"attachment":"View Matrix"},"pMatrix":{"attachment":"Projection Matrix"}}},"R2T":{"value":{"renderedTexture":{"attachment":"Base Pass color"}}}}}